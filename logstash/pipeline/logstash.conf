# Logstash Pipeline 配置文件
# 适用于Spring Boot应用日志收集

input {
  # Beats输入 (用于Filebeat)
  beats {
    port => 5044
  }

  # TCP输入 (用于应用直接发送日志)
  tcp {
    port => 5000
    codec => json_lines
  }

  # UDP输入 (用于syslog)
  udp {
    port => 5000
    codec => json_lines
  }

  # HTTP输入 (用于REST API日志收集)
  http {
    port => 8080
    codec => json
  }
}

filter {
  # 处理Spring Boot日志格式
  if [fields][log_type] == "springboot" {
    grok {
      match => {
        "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} %{NUMBER:pid} --- \\[%{DATA:thread}\\] %{DATA:logger} : %{GREEDYDATA:log_message}"
      }
    }

    date {
      match => [ "timestamp", "yyyy-MM-dd HH:mm:ss.SSS" ]
    }

    mutate {
      add_field => { "application" => "%{[fields][app_name]}" }
      add_field => { "environment" => "%{[fields][env]}" }
    }
  }

  # 处理JSON格式日志
  if [message] =~ /^\\{.*\\}$/ {
    json {
      source => "message"
    }
  }

  # 添加通用字段
  mutate {
    add_field => { "[@metadata][index_prefix]" => "logstash" }
    add_field => { "received_at" => "%{@timestamp}" }
  }
}

output {
  # 输出到Elasticsearch
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    user => "logstash_system"
    password => "logstash123456"
    index => "%{[@metadata][index_prefix]}-%{+YYYY.MM.dd}"
  }

  # 调试输出 (可选，生产环境建议关闭)
  # stdout { codec => rubydebug }
}